#!/bin/bash
#SBATCH --job-name=partfield_pipeline
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --mem-per-cpu=8000m
#SBATCH --time=00:45:00
#SBATCH --account=eecs442f25_class
#SBATCH --partition=gpu_mig40,spgpu
#SBATCH --gres=gpu:1

#sbatch --output=partfield_pipeline_${BATCH_ID}.log pipeline_infere.sh BATCH_ID
# ======================
# ç¯å¢ƒ
# ======================
source ~/.bashrc
conda activate partfield

# ======================
# å‚æ•°
# ======================
BATCH_ID=$1
SCRATCH_BASE="/scratch/eecs442f25_class_root/eecs442f25_class/jonzhe"

DATA_BASE="$SCRATCH_BASE/data"
GLB_DIR="$DATA_BASE/objaverse_glbs/batch_${BATCH_ID}"

OUTPUT_BASE="$SCRATCH_BASE/output"
FEAT_DIR="$OUTPUT_BASE/partfield_features/batch_${BATCH_ID}"

mkdir -p "$GLB_DIR" "$FEAT_DIR"

echo "Directories:"
echo "  GLB_DIR     = $GLB_DIR"
echo "  FEAT_DIR    = $FEAT_DIR"

# ======================
# ä¸‹è½½ GLB
# ======================
python download.py \
    --batch "$BATCH_ID" \
    --batch_size 200 \
    --data_dir "$DATA_BASE"

# ======================
# PartField æ¨ç†
# ======================
echo "ğŸ“Œ Running PartField inference..."
python partfield_inference.py \
    -c configs/final/demo.yaml \
    --opts continue_ckpt model/model_objaverse.ckpt \
    result_name "$FEAT_DIR" \
    dataset.data_path "$GLB_DIR"

cd "$FEAT_DIR"
rm -f *.ply

# ======================
# å‹ç¼©ç»“æœ
# ======================
echo "ğŸ“¦ Compressing results in $FEAT_DIR ..."

TAR_NAME="partfield_batch_${BATCH_ID}.tar.gz"
CHECKSUM_NAME="${TAR_NAME}.sha256"

# æ‰“åŒ…
tar -czvf "$TAR_NAME" ./*.npy

# ç”Ÿæˆæ ¡éªŒæ–‡ä»¶ï¼ˆå¼ºçƒˆæ¨èï¼‰
sha256sum "$TAR_NAME" > "$CHECKSUM_NAME"

echo "ğŸ“¦ Created archive: $TAR_NAME"
echo "ğŸ” SHA256 saved  : $CHECKSUM_NAME"

# å¦‚éœ€åˆ é™¤åŸå§‹æ–‡ä»¶ï¼Œå¯æ‰“å¼€ä¸‹é¢ä¸¤è¡Œ
echo "ğŸ§¹ Cleaning original .npy files..."
rm -f ./*.npy
rm -rf "$DATA_BASE/objaverse_glbs/batch_${BATCH_ID}"

echo "ğŸ‰ All done!"
